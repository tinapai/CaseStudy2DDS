---
title: "EDA"
author: "Tina Pai"
date: "4/13/2020"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)



```

## EDA
```{r}
employees <- read.csv("CaseStudy2-data.csv")

str(employees)
colSums(is.na(employees))
summary(employees$MonthlyIncome)
summary(employees$Attrition)
#useless variable with one value across the whole thing
employees$Over18 <- NULL

```


Are any ordinal variables going in as continuous right now?
yes
```{r}
employees$JobInvolvement[which(employees$JobInvolvement == 1)] = 'Low'
employees$JobInvolvement[which(employees$JobInvolvement == 2)] = 'Medium'
employees$JobInvolvement[which(employees$JobInvolvement == 3)] = 'High'
employees$JobInvolvement[which(employees$JobInvolvement == 4)] = 'Very High'
employees$JobInvolvement = as.factor(employees$JobInvolvement)
summary(employees$JobInvolvement)

employees$JobSatisfaction[which(employees$JobSatisfaction == 1)] = 'Low'
employees$JobSatisfaction[which(employees$JobSatisfaction == 2)] = 'Medium'
employees$JobSatisfaction[which(employees$JobSatisfaction == 3)] = 'High'
employees$JobSatisfaction[which(employees$JobSatisfaction == 4)] = 'Very High'
employees$JobSatisfaction = as.factor(employees$JobSatisfaction)
summary(employees$JobSatisfaction)

employees$PerformanceRating[which(employees$PerformanceRating == 1)] = 'Low'
employees$PerformanceRating[which(employees$PerformanceRating == 2)] = 'Good'
employees$PerformanceRating[which(employees$PerformanceRating == 3)] = 'Excellent'
employees$PerformanceRating[which(employees$PerformanceRating == 4)] = 'Outstanding'
employees$PerformanceRating = as.factor(employees$PerformanceRating)
summary(employees$PerformanceRating)

employees$RelationshipSatisfaction[which(employees$RelationshipSatisfaction == 1)] = 'Low'
employees$RelationshipSatisfaction[which(employees$RelationshipSatisfaction == 2)] = 'Medium'
employees$RelationshipSatisfaction[which(employees$RelationshipSatisfaction == 3)] = 'High'
employees$RelationshipSatisfaction[which(employees$RelationshipSatisfaction == 4)] = 'Very High'
employees$RelationshipSatisfaction = as.factor(employees$RelationshipSatisfaction)
summary(employees$RelationshipSatisfaction)

employees$WorkLifeBalance[which(employees$WorkLifeBalance == 1)] = 'Bad'
employees$WorkLifeBalance[which(employees$WorkLifeBalance == 2)] = 'Good'
employees$WorkLifeBalance[which(employees$WorkLifeBalance == 3)] = 'Better'
employees$WorkLifeBalance[which(employees$WorkLifeBalance == 4)] = 'Best'
employees$WorkLifeBalance = as.factor(employees$WorkLifeBalance)
summary(employees$WorkLifeBalance)

employees$Education[which(employees$Education == 1)] = 'Below College'
employees$Education[which(employees$Education == 2)] = 'College'
employees$Education[which(employees$Education == 3)] = 'Bachelor'
employees$Education[which(employees$Education == 4)] = 'Master'
employees$Education[which(employees$Education == 5)] = 'Doctor'
employees$Education = as.factor(employees$Education)
summary(employees$WorkLifeBalance)

employees$EnvironmentSatisfaction[which(employees$EnvironmentSatisfaction == 1)] = 'Low'
employees$EnvironmentSatisfaction[which(employees$EnvironmentSatisfaction == 2)] = 'Medium'
employees$EnvironmentSatisfaction[which(employees$EnvironmentSatisfaction == 3)] = 'High'
employees$EnvironmentSatisfaction[which(employees$EnvironmentSatisfaction == 4)] = 'Very High'
employees$EnvironmentSatisfaction = as.factor(employees$EnvironmentSatisfaction)
summary(employees$EnvironmentSatisfaction)

employees$StockOptionLevel = factor(employees$StockOptionLevel)
summary(employees$StockOptionLevel)
```


Highest job satisfaction vs job role
```{r jobsatisfaction}
library(ggmosaic)

ggplot(data = employees) +
   geom_mosaic(aes(x = product(JobSatisfaction, JobRole), fill=JobRole), na.rm=TRUE) + labs(x = "Job Role", title='Job Satisfaction in Job Roles', y='Job Satisfaction')+
theme(axis.text.x = element_text(angle = 90))

#Chi square says no significant difference in job satisfaction across education fields
table(employees$JobSatisfaction, employees$JobRole)
chisq.test(table(employees$JobSatisfaction, employees$JobRole))

```
job role vs education field: Those who got Marketing or Human Resources degrees were all either in HR, management, or sales; all the research-related jobs had science, medical, technical, or other degree.
```{r}
ggplot(data = employees) +
   geom_mosaic(aes(x = product(EducationField, JobRole), fill=EducationField), na.rm=TRUE) + labs(y = "Education Field", title='Education Field of Job Roles', x='Job Role') +
theme(axis.text.x = element_text(angle = 90))
```

income job role: HR, lab technician, research scientist, and sales representatives make the least money. Managers and Research directors make the most money. Healthcare representatives, Manufacturing directors, and sales executives make in the middle.
```{r}
ggplot(data = employees, aes(x=JobRole, y=MonthlyIncome, fill=JobRole)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90)) +
  ggtitle("Incomes of Job Roles")
```

Working years vs job roles: Sales represntative and HR seem to be the most entry-level type job, whereas manager and director have generally been working a longer time than those in other roles.
```{r}
ggplot(data = employees, aes(x=JobRole, y=TotalWorkingYears, fill=JobRole)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90)) +
  ggtitle("How Long People of Job Roles Have Worked")
```

JobInvolvement of job roles: All the job roles have the same level of job involvement, at least according to this data.

```{r}
ggplot(data = employees) +
   geom_mosaic(aes(x = product(factor(JobInvolvement), JobRole), fill=factor(JobInvolvement)), na.rm=TRUE) + labs(y = "Job Involvement", title='Involvment of Job Roles', x='Job Role') +
theme(axis.text.x = element_text(angle = 90))
```


What continuous variables have a difference in distribution of attrition?
pairs plots continuous

```{r, message=FALSE}
library(GGally)

#there's 22 continuous variables
employees %>%
  select_if(is.numeric) %>%
  dim()

employees %>%
  select_if(is.numeric) %>%
  select(1:5) %>%
  mutate(Attrition = employees$Attrition) %>%
  sample_n(200) %>%
  ggpairs(aes(colour = Attrition)) + 
  ggtitle("Pairs Plot")

employees %>%
  select_if(is.numeric) %>%
  select(6:10) %>%
  mutate(Attrition = employees$Attrition) %>%
  sample_n(200) %>%
  ggpairs(aes(colour = Attrition)) + 
  ggtitle("Pairs Plot")

employees %>%
  select_if(is.numeric) %>%
  select(11:16) %>%
  mutate(Attrition = employees$Attrition) %>%
  sample_n(200) %>%
  ggpairs(aes(colour = Attrition)) + 
  ggtitle("Pairs Plot")

employees %>%
  select_if(is.numeric) %>%
  select(17:22) %>%
  mutate(Attrition = employees$Attrition) %>%
  sample_n(200) %>%
  ggpairs(aes(colour = Attrition)) + 
  ggtitle("Pairs Plot")

```

Check for multicollinearity between continuous variables
```{r}

library(corrplot)
## corrplot 0.84 loaded
M <- employees %>%
  select_if(is.numeric) %>%
  cor()

corrplot(M, method = "circle")
```


What categorical variables have a difference in distribution in response?
```{r, message=FALSE}

#there's 14 categorical variables
employees %>%
  select_if(is.factor) %>%
  dim()

categs <- names(select_if(employees, is.factor))

for(i in 1:length(categs)){
  print(employees %>%
    ggplot(aes(x = eval(parse(text=categs[i])), fill = Attrition)) +
    geom_bar(position = "fill") +
    xlab(categs[i])
  )
}

```

setting up balanced train test split
```{r}

split_train_test <- function(df) {
  # dataset with "no"
  data_no = df[which(df$Attrition=="No"),]
  # dataset with "yes"
  data_yes = df[which(df$Attrition=="Yes"),]
  
  #making more folds on No to balance the number with Yes 
  folds_no = createFolds(data_no$Attrition, k=8)
  folds_yes = createFolds(data_yes$Attrition, k=2)
  length(folds_no$Fold1)
  length(folds_no$Fold2)
  length(folds_yes$Fold1)
  length(folds_yes$Fold2)
  
  #Train
  train_no = data_no[folds_no$Fold1,]
  train_yes = data_yes[folds_yes$Fold1,]
  train = rbind(train_no, train_yes)
  
  #Test
  test_no = data_no[c(folds_no$Fold2, folds_no$Fold3, folds_no$Fold4, folds_no$Fold5),]
  test_yes = data_yes[folds_yes$Fold2,]
  test = rbind(test_no, test_yes)
  
  return(list(train, test))
}
```

Predict attrition - Naive Bayes
```{r}
library(caret)
library(e1071)
library(ROCR)
library(plotROC)

#naive bayes
#balanced training set
train1 <- split_train_test(employees)[[1]]
test1 <- split_train_test(employees)[[2]]
model.nb1 <- naiveBayes(Attrition ~ ., data=train1)
preds.nb1 <- predict(model.nb1, test1)
confusionMatrix(table(preds.nb1, test1$Attrition))
preds.nb1 <- predict(model.nb1, test1, type = "raw")
preds.nb1 <- prediction(preds.nb1[,2], test1$Attrition)
roc.perf_1 = performance(preds.nb1, measure = "tpr", x.measure = "fpr")

#unbalanced training set
folds <- createFolds(employees$Attrition, k=2)
train2 <- employees[folds$Fold1,]
test2 <- employees[folds$Fold2,]
model.nb2 <- naiveBayes(Attrition ~ ., data=train2)
preds.nb2 <- predict(model.nb2, test2)
confusionMatrix(table(preds.nb2, test2$Attrition))
preds.nb2 <- predict(model.nb2, test2, type = "raw")
preds.nb2 <- prediction(preds.nb2[,2], test2$Attrition)
roc.perf_2 = performance(preds.nb2, measure = "tpr", x.measure = "fpr")

#the balanced one definitely looks better and .25 seems a good threshold
plot(roc.perf_1, col="red")
plot(roc.perf_2, add = TRUE, col="blue")
```

make numeric and make standardize scale data for KNN
```{r}
#re-read in data
employees_num <- read.csv("CaseStudy2-data.csv")

#get rid of useless variables
employees_num$Over18 <- NULL
employees_num$ID <- NULL

#numericize categorical variables
employees_num$BusinessTravel = as.numeric(employees_num$BusinessTravel)
employees_num$Department = as.numeric(employees_num$Department)
employees_num$EducationField = as.numeric(employees_num$EducationField)
employees_num$Gender = as.numeric(employees_num$Gender)
employees_num$JobRole = as.numeric(employees_num$JobRole)
employees_num$MaritalStatus = as.numeric(employees_num$MaritalStatus)
employees_num$OverTime = as.numeric(employees_num$OverTime)

n <- dim(employees_num)[2]

#scale
employees_z <- employees_num %>%
mutate(zAge = scale(Age))  %>% 
mutate(zBusinessTravel = scale(BusinessTravel)) %>%
mutate(zDailyRate = scale(DailyRate)) %>%
mutate(zDepartment = scale(Department)) %>%
mutate(zDistanceFromHome = scale(DistanceFromHome)) %>%
mutate(zEducation = scale(Education)) %>%
mutate(zEducationField = scale(EducationField)) %>%
mutate(zEmployeeCount = scale(EmployeeCount)) %>%
mutate(zEmployeeNumber = scale(EmployeeNumber)) %>%
mutate(zEnvironmentSatisfaction = scale(EnvironmentSatisfaction)) %>%
mutate(zGender = scale(Gender)) %>%
mutate(zHourlyRate = scale(HourlyRate))           %>%
mutate(zJobInvolvement = scale(JobInvolvement)) %>%
mutate(zJobLevel = scale(JobLevel)) %>%
mutate(zJobRole = scale(JobRole)) %>%
mutate(zJobSatisfaction = scale(JobSatisfaction)) %>%
mutate(zMaritalStatus = scale(MaritalStatus)) %>%
mutate(zMonthlyIncome = scale(MonthlyIncome)) %>%
mutate(zMonthlyRate = scale(MonthlyRate)) %>%
mutate(zNumCompaniesWorked = scale(NumCompaniesWorked)) %>%
mutate(zOverTime = scale(OverTime)) %>%
mutate(zPercentSalaryHike = scale(PercentSalaryHike)) %>%
mutate(zPerformanceRating = scale(PerformanceRating)) %>%
mutate(zRelationshipSatisfaction = scale(RelationshipSatisfaction)) %>%
mutate(zStandardHours = scale(StandardHours)) %>%
mutate(zStockOptionLevel = scale(StockOptionLevel)) %>%
mutate(zTotalWorkingYears = scale(TotalWorkingYears)) %>%
mutate(zTrainingTimesLastYear = scale(TrainingTimesLastYear)) %>%
mutate(zWorkLifeBalance = scale(WorkLifeBalance)) %>%
mutate(zYearsAtCompany = scale(YearsAtCompany)) %>%
mutate(zYearsInCurrentRole = scale(YearsInCurrentRole)) %>%
mutate(zYearsSinceLastPromotion = scale(YearsSinceLastPromotion)) %>%
mutate(zYearsWithCurrManager = scale(YearsWithCurrManager))

nz <- dim(employees_z)[2]
employees_z <- employees_z[,c((n+1):nz)]
employees_z$Attrition = employees$Attrition
#get rid of nans
colSums(is.na(employees_z))
employees_z$zStandardHours <- NULL
employees_z$zEmployeeCount <- NULL
str(employees_z)

```


Predict attrition - KNN
```{r knn}
#KNN
##load the package class
 library(class)

train <- split_train_test(employees_num)[[1]]
test <- split_train_test(employees_num)[[2]]

##run knn k=8 and make ROC--it looks really bad
preds.knn <- knn(train[, names(train) != "Attrition"], test[, names(train) != "Attrition"], cl=train$Attrition, k=8, prob=TRUE)
prob.knn <- attr(preds.knn, "prob")
preds.knn <- prediction(prob.knn, test$Attrition)
roc.perf_knn = performance(preds.knn, measure = "tpr", x.measure = "fpr")
auc <- performance(preds.knn, measure = "auc")
auc <- auc@y.values
plot(roc.perf_knn, colorize = TRUE)

auc.knns <- c()
for(i in 1:80) {
#train test split
train <- split_train_test(employees_num)[[1]]
test <- split_train_test(employees_num)[[2]]

##get auc of knn
preds.knn <- knn(train[, names(train) != "Attrition"], test[, names(train) != "Attrition"], cl=train$Attrition, k=i, prob=TRUE)
prob.knn <- attr(preds.knn, "prob")
preds.knn <- prediction(prob.knn, test$Attrition)
roc.perf_knn = performance(preds.knn, measure = "tpr", x.measure = "fpr")
auc <- performance(preds.knn, measure = "auc")
auc <- auc@y.values
auc.knns <- c(auc.knns, auc)
}
plot(x=1:80, y=auc.knns, xlab="k", main = "AUCs of KNN models with k=[1,80]")
#all the KNN models are bad

#second time, this time with scaled variables

train <- split_train_test(employees_z)[[1]]
test <- split_train_test(employees_z)[[2]]

str(train)
str(test)
##run knn k=8 and make ROC
preds.knn <- knn(train[, names(train) != "Attrition"], test[, names(train) != "Attrition"], cl=as.factor(train$Attrition), k=8, prob=TRUE)
prob.knn <- attr(preds.knn, "prob")
preds.knn <- prediction(prob.knn, test$Attrition)
roc.perf_knn = performance(preds.knn, measure = "tpr", x.measure = "fpr")
auc <- performance(preds.knn, measure = "auc")
auc <- auc@y.values
auc.knns <- c(auc.knns, auc)
plot(roc.perf_knn, colorize = TRUE)

auc.knns <- c()
for(i in 1:80) {
#train test split
train <- split_train_test(employees_num)[[1]]
test <- split_train_test(employees_num)[[2]]

##get auc of knn for many ks
preds.knn <- knn(train[, names(train) != "Attrition"], test[, names(train) != "Attrition"], cl=train$Attrition, k=i, prob=TRUE)
prob.knn <- attr(preds.knn, "prob")
preds.knn <- prediction(prob.knn, test$Attrition)
roc.perf_knn = performance(preds.knn, measure = "tpr", x.measure = "fpr")
auc <- performance(preds.knn, measure = "auc")
auc <- auc@y.values
auc.knns <- c(auc.knns, auc)
}
plot(x=1:80, y=auc.knns, xlab="k", main = "AUCs of KNN models with k=[1,80]")
#they're all still bad
```


```{r categorize}
#RF
library(randomForest)

train <- split_train_test(employees)[[1]]
test <- split_train_test(employees)[[2]]

model.rf <- randomForest(Attrition ~ ., data = train, importance = TRUE)
preds.rf <- predict(model.rf, test)

confusionMatrix(table(preds.rf, test$Attrition), positive = "Yes")

prob.rf <- predict(model.rf, test, type = "prob")
preds.rf <- prediction(prob.rf[,2], test$Attrition)
roc.rf = performance(preds.rf, measure = "tpr", x.measure = "fpr")

#the balanced one definitely looks better and .25 seems a good threshold
plot(roc.perf_1, col="red")
plot(roc.rf, add = TRUE, col="blue")

```

Random forest wins!

Regression time

What continuous variables have a difference in distribution of the Monthly Income?
pairs plots continuous

```{r, message=FALSE}
library(GGally)

employees %>%
  ggplot(aes(x=MonthlyIncome)) +
  geom_histogram()

employees %>%
  select_if(is.numeric) %>%
  select(1:5) %>%
  mutate(MonthlyIncome = employees$MonthlyIncome) %>%
  sample_n(200) %>%
  ggpairs() + 
  ggtitle("Pairs Plot")

employees %>%
  select_if(is.numeric) %>%
  select(6:10) %>%
  mutate(MonthlyIncome = employees$MonthlyIncome) %>%
  sample_n(200) %>%
  ggpairs() + 
  ggtitle("Pairs Plot")

employees %>%
  select_if(is.numeric) %>%
  select(11:15) %>%
  mutate(MonthlyIncome = employees$MonthlyIncome) %>%
  sample_n(200) %>%
  ggpairs() + 
  ggtitle("Pairs Plot")

employees %>%
  select_if(is.numeric) %>%
  select(16:20) %>%
  mutate(MonthlyIncome = employees$MonthlyIncome) %>%
  sample_n(200) %>%
  ggpairs() + 
  ggtitle("Pairs Plot")

employees %>%
  select_if(is.numeric) %>%
  select(21:27) %>%
  mutate(MonthlyIncome = employees$MonthlyIncome) %>%
  sample_n(200) %>%
  ggpairs() + 
  ggtitle("Pairs Plot")
```

What categorical variables have a difference in distribution in response?
```{r, message=FALSE}

#there's 16 categorical variables
employees %>%
  select_if(is.factor) %>%
  dim()

categs <- names(select_if(employees, is.factor))

for(i in 1:length(categs)){
  print(employees %>%
    ggplot(aes(x = eval(parse(text=categs[i])), y=MonthlyIncome)) +
    geom_boxplot() +
    xlab(categs[i])
  )
}

```

Make train test split
```{r}
folds <- createFolds(employees$ID, k=2)
train <- employees[folds$Fold1,]
test <- employees[folds$Fold2,]

```

manually selected variables based on EDA plots
```{r}
#make train test split
folds <- createFolds(employees$ID, k=2)
train <- employees[folds$Fold1,]
test <- employees[folds$Fold2,]

#fit the manual model
lm.manual <- lm(MonthlyIncome ~ Age + EmployeeNumber + NumCompaniesWorked +
                  TotalWorkingYears + YearsAtCompany + YearsInCurrentRole + YearsSinceLastPromotion + Attrition + BusinessTravel + Department + Education + EducationField + JobRole +  StockOptionLevel, data=train)

#check residuals and summary
plot(lm.manual)
summary(lm.manual)

#prediction error
preds.lm.manual <- predict(lm.manual, test)
print("RMSE:")
RMSE(preds.lm.manual, test$MonthlyIncome)
```

full model
```{r}
#make train test split
folds <- createFolds(employees$ID, k=2)
train <- employees[folds$Fold1,]
test <- employees[folds$Fold2,]

#fit the model
lm.full <- lm(MonthlyIncome ~ ., data=train)

#check residuals and summary
plot(lm.full)
summary(lm.full)

#prediction error
preds.lm.full <- predict(lm.full, test)
print("RMSE:")
RMSE(preds.lm.full, test$MonthlyIncome)
```

LASSO
```{r}
library(glmnet)

#make train test split
folds <- createFolds(employees$ID, k=2)
train <- employees[folds$Fold1,]
test <- employees[folds$Fold2,]

#find the lasso variable choices
x_vars <- model.matrix(MonthlyIncome~. , employees)[,-1]
cvfit <- cv.glmnet(x_vars, employees$MonthlyIncome)
coef(cvfit, s = "lambda.1se")

#fit the model
lm.lasso <- lm(MonthlyIncome ~ Attrition+BusinessTravel+ DistanceFromHome + Education + EmployeeNumber + EnvironmentSatisfaction + Gender + JobLevel + JobRole + MonthlyRate + RelationshipSatisfaction+ TotalWorkingYears + YearsInCurrentRole + YearsSinceLastPromotion + YearsWithCurrManager, data=train)

#check residuals and summary
plot(lm.lasso)
summary(lm.lasso)

#prediction error
preds.lm.lasso <- predict(lm.lasso, test)
print("RMSE:")
RMSE(preds.lm.lasso, test$MonthlyIncome)
```

Forward step model
```{r}
#make train test split
folds <- createFolds(employees$ID, k=2)
train <- employees[folds$Fold1,]
test <- employees[folds$Fold2,]

#find the forward selection variables
model.null<-lm(MonthlyIncome ~ 1, data=employees)
model.complex <- lm(MonthlyIncome ~ (Age + EmployeeNumber + NumCompaniesWorked +
                  TotalWorkingYears + YearsAtCompany + YearsInCurrentRole + YearsSinceLastPromotion + Attrition + BusinessTravel + Department + Education + EducationField + JobRole +  StockOptionLevel)^2 + ., data=train)
model.forward <- step(model.null,
                   scope = list(upper=model.complex),
                   direction="forward",
                   data=employees)
coef(model.forward)

#fit the model
lm.forward <- lm(MonthlyIncome ~ JobLevel + JobRole + TotalWorkingYears + BusinessTravel + 
    DailyRate + Gender + ID + MonthlyRate + Department + JobRole:TotalWorkingYears + 
    TotalWorkingYears:BusinessTravel, data=train)

#check residuals and summary
summary(lm.forward)
plot(lm.forward)

#prediction error
preds.lm.forward <- predict(lm.forward, test)
print("RMSE:")
RMSE(preds.lm.forward, test$MonthlyIncome)
```

EDA for KNN for income
LR EDA

```{r EDALR}

 #Plots of working years vs income, colored by various elements to see if they make a good split
 employees  %>%
   mutate(PromotionBins = cut(employees$YearsSinceLastPromotion, 10)) %>%
   ggplot(aes(x=TotalWorkingYears, MonthlyIncome, colour=PromotionBins)) +
   geom_point()

 employees  %>%
   mutate(TenureBins = cut(employees$YearsAtCompany, 10)) %>%
   ggplot(aes(x=TotalWorkingYears, MonthlyIncome, colour=TenureBins)) +
   geom_point()
   
 employees  %>%
   mutate(ManagerBins = cut(employees$YearsWithCurrManager, 10)) %>%
   ggplot(aes(x=TotalWorkingYears, MonthlyIncome, colour=ManagerBins)) +
   geom_point()
   
 employees  %>%
   mutate(RoleBins = cut(employees$YearsInCurrentRole, 10)) %>%
   ggplot(aes(x=TotalWorkingYears, MonthlyIncome, colour=RoleBins)) +
   geom_point()

 employees  %>%
   ggplot(aes(x=TotalWorkingYears, MonthlyIncome, colour=factor(JobLevel))) +
   geom_point()

 employees  %>%
   mutate(IncomeBins = cut(employees$MonthlyIncome, 10)) %>%
   ggplot(aes(x=TotalWorkingYears, JobLevel, colour=IncomeBins)) +
   geom_point()

 employees_yrs <- employees  %>%
   select(c(TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager))

 employees_pcs <- prcomp(employees_yrs, scale = TRUE)

 employees %>%
   ggplot(aes(x=employees_pcs$x[,1], y=MonthlyIncome)) +
   geom_point()

 employees %>%
   mutate(IncomeBins = cut(employees$MonthlyIncome, 10)) %>%
   mutate(PC1 = employees_pcs$x[,1]) %>%
   mutate(PC2 = employees_pcs$x[,2]) %>%
 ggplot(aes(x=PC1, y=PC2, colour=IncomeBins)) +
   geom_point()
```

KNN regression
```{r}
employees_z2 <- employees_z %>%
  mutate(MonthlyIncome = employees_num$MonthlyIncome) %>%
  mutate(zAttrition = scale(as.numeric(Attrition)))
employees_z2$Attrition <- NULL
employees_z2$zMonthlyIncome <- NULL
employees_z2$PC1 <- employees_pcs$x[,1]
employees_z2$PC2 <- employees_pcs$x[,2]
employees_z2$PC3 <- employees_pcs$x[,3]

#train test split
folds <- createFolds(employees_z2$MonthlyIncome, k=2)
train <- employees_z2[folds$Fold1,]
test <- employees_z2[folds$Fold2,]

##run knn with everything
preds.knn <- knn(train[, names(train) != "MonthlyIncome"], test[, names(train) != "MonthlyIncome"], cl=train$MonthlyIncome, k=10)
preds.knn <- as.numeric(preds.knn)
plot(x=preds.knn, y=test$MonthlyIncome)
#gross
print("RMSE:")
RMSE(preds.knn, test$MonthlyIncome)

##run knn with just a few manually selected variables
preds.knn <- knn(train[, c("zJobRole", "zJobLevel", "zTotalWorkingYears")], test[, c("zJobRole", "zJobLevel", "zTotalWorkingYears")], cl=train$MonthlyIncome, k=10)
preds.knn <- as.numeric(preds.knn)
plot(x=preds.knn, y=test$MonthlyIncome)
print("RMSE:")
RMSE(preds.knn, test$MonthlyIncome)
#not bad

##run knn with even fewer manually selected variables
preds.knn <- knn(train[, c("zJobLevel", "zTotalWorkingYears")], test[, c("zJobLevel", "zTotalWorkingYears")], cl=train$MonthlyIncome, k=10)
preds.knn <- as.numeric(preds.knn)
plot(x=preds.knn, y=test$MonthlyIncome)
print("RMSE:")
RMSE(preds.knn, test$MonthlyIncome)
#not bad

##run knn with PCs
preds.knn <- knn(train[, c("zJobRole", "zJobLevel", "PC1", "PC2", "PC3")], test[, c("zJobRole", "zJobLevel", "PC1", "PC2", "PC3")], cl=train$MonthlyIncome, k=10)
preds.knn <- as.numeric(preds.knn)
plot(x=preds.knn, y=test$MonthlyIncome)
print("RMSE:")
RMSE(preds.knn, test$MonthlyIncome)
```

